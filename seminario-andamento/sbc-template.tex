\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  

     
\sloppy

\title{Seminário de Andamento\\Escalonamento Adaptativo para o Apache Hadoop}

\author{Guilherme Weigert Cassales\inst{1}, Andrea Schwertner Charão\inst{1}}

\address{Laboratório de Sistemas Computacionais\\Universidade Federal de Santa Maria (UFSM)\\Santa Maria -- RS -- Brazil
  \email{\{cassales,andrea\}@inf.ufsm.br}
}

\begin{document} 

\maketitle
\begin{abstract}
This article proposes to improve Apache Hadoop scheduling through the usage of context-awareness. Apache Hadoop is the most popular implementation of the MapReduce paradigm for distributed computing, but its design doesn't adapt automatically to computing nodes' context and capabilities. By introducing context-awareness into Hadoop, we intent to dynamically adapt its scheduling to the execution environment. The solution has been incorporated into Hadoop and evaluated through controlled experiments. The experiments demonstrate that context-awareness provides comparative performance gains, especially when part of the resources disappear during execution.
\end{abstract}
     
\begin{resumo} 
Este trabalho propõe uma melhoria no escalonamento do Apache Hadoop através da utilização de informações de contexto sobre os nós de um \textit{cluster}. O Apache Hadoop é a implementação mais popular do paradigma MapReduce em computação distribuída, porém possui alguns problemas de performance em ambientes dinâmicos. Ao introduzir sensibilidade ao contexto no Hadoop, espera-se que o escalonamento das aplicações adapte-se às mudanças do ambiente. A solução foi implementada no Apache Hadoop e testes preliminares indicam que houve uma melhora de performance, especialmente quando parte dos recursos desaparece durante a execução.
\end{resumo}


\section{Introdução}
Apache Hadoop é um \textit{framework} de computação paralela e distribuída para processamento de grandes conjuntos de dados e implementa o paradigma de programação \mbox{MapReduce} \cite{Dean2008}. O Apache Hadoop é projetado para ser escalável de um único servidor a milhares de máquinas, cada uma oferecendo processamento e armazenamento local.

Sem uma configuração específica pelo administrador, o Apache Hadoop assume que está sendo utilizado em um \textit{cluster} homogêneo para execução de aplicações \mbox{MapReduce}. Uma vez que a performance geral do \textit{cluster} está ligada ao escalonamento de tarefas, o Hadoop pode ser seriamente afetado quando executado em ambientes que não satisfaçam a suposição feita no projeto do \textit{framework}, ou seja, em ambientes dinâmicos ou heterogêneos.

Esta é uma preocupação especial quando tenta-se utilizar o Hadoop em grids pervasivos. Grids pervasivos são uma alternativa aos custosos \textit{clusters} dedicados, dado que a aquisição e manutenção de um \textit{cluster} dedicado continua alta e dissuasiva para muitas organizações. De acordo com \cite{Parashar2010}, grids pervasivos representam a generalização  extrema do conceito de grid por possuírem recursos pervasivos, ou seja, recursos computacionais ociosos incorporados em ambientes pervasivos são requisitados com objetivo de processar tarefas de maneira distribuída. 

Estes grids podem ser vistos como grids formados por recursos existentes (desktops, servidores, etc.) que ocasionalmente contribuem para o poder de processamento do grid. Estes recursos são inerentemente heterogêneos e potencialmente móveis, entrando e saindo do grid dinamicamente. Sabendo disto, é possível afirmar que grids pervasivos são, essencialmente, ambientes heterogêneos, dinâmicos e compartilhados. Ainda, com base nesta afirmação, seu gerenciamento eficiente torna-se um trabalho muito complexo, afetando severamente o escalonamento de tarefas \cite{Nascimento}.

Muitos trabalhos propuseram-se a melhorar a adaptabilidade do \textit{framework} Apache Hadoop em ambientes que divergem da suposição inicial, cada um possuindo sua própria proposta e objetivos \cite{Kumar2012, Zaharia2008, Rasooli2012, Sandholm2010, 3PGCIC}.

Sabe-se que, o Apache Hadoop é baseado em configuração estática de arquivos e que as versões correntes não adaptam-se a variações de recursos ao longo do tempo. Além disto, os procedimentos de instalação forçam o administrador a definir manualmente as características de cada recurso em potencial, como a memória e o número de cores de cada máquina, tornando a tarefa difícil e demorada em ambientes heterogêneos. Todos estes fatores impedem a utilização da capacidade total do Hadoop em ambientes voláteis, portanto, é essencial possuir sensibilidade ao contexto para tornar esta adaptação possível.

Este trabalho propõe-se a introduzir sensibilidade ao contexto nos mecanismos de escalonamento do Apache Hadoop através da coleta e transmissão de dados. Buscou-se atingir estes objetivos com o mínimo de intrusão e alterações nos mecanismos chave de escalonamento possível. 

%The rest of the paper is organized as follows: Section \ref{sec:refteo} presents Apache Hadoop architecture and scheduling mechanisms. Section \ref{sec:related} discusses related work, focusing on
%context-awareness and on other works that try to improve Hadoop schedulers. Section \ref{sec:desenv} presents our proposal of context-aware scheduling, while Section \ref{sec:exper} presents the experiments conducted and the achieved results. We finally conclude this paper in Section \ref{sec:concl}.

\section{Revisão de literatura}
É necessário definir alguns termos, técnicas e/ou ferramentas para o entendimento do trabalho. Por exemplo, a conceituação formal de sensibilidade ao contexto é muito importante, uma vez que constitue-se da técnica de obtenção dos dados. Como complemento à sensibilidade ao contexto define-se o que é o ZooKeeper, a ferramenta utilizada para transmissão dos dados coletados. Além disso, a compreensão de como o Apache Hadoop e seu escalonamento funcionam, bem como quais trabalhos já foram feitos neste âmbito, são relevantes.

\subsection{Sensibilidade ao contexto}
Sensibilidade ao contexto é a capacidade de uma aplicação ou \textit{software} de detectar e responder às mudanças do ambiente \cite{Maamar}. Um sistema sensível ao contexto é capaz de adaptar suas operações ao estado corrente sem intervenção humana, consequentemente melhorando a usabilidade e eficiência deste sistema \cite{Baldauf}. Em grids pervasivos, o escalonamento é uma tarefa que pode ser beneficiada com a inclusão de sensibilidade ao contexto através da coleta de dados sobre os recursos do grid e tomada de decisões baseadas nestes dados.


\subsection{Apache Hadoop e escalonamento}
O \textit{framework} Apache Hadoop é organizado numa arquitetura de mestre-escravo e possui dois serviços principais, o serviço de armazenamento (HDFS) e o de processamento (YARN). Cada serviço possui mestre e escravos independentes como apresentado na Figura \ref{fig:ArquiteturaHadoop}, onde é possível notar que os serviços NameNode e ResourceManager, mestres do HDFS e YARN respectivamente, e os seus respectivos escravos DataNode e NodeManager. Outro componente que aparece na figura é o ApplicationMaster, este componente é responsável pelo gerenciamento interno de cada \textit{job}, também chamado de escalonamento de \textit{tasks} ou tarefas. Entende-se \textit{task} como uma fração do processamento das aplicações, ou seja, cada tarefa de Map ou Reduce corresponde a uma \textit{task}. Enquanto o ApplicationMaster gerencia as tarefas, é função do ResourceManager gerenciar os \textit{jobs} ou aplicações. Finalmente, o último componente a aparecer na figura é o Container, o qual representa uma alocação de recursos em um nó qualquer do \textit{cluster}. A importância do container vem do fato de que todas as tarefas são executadas em uma instância de container.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\textwidth]{figs/HadoopArch.pdf}
\caption{Arquitetura geral do Apache Hadoop}
\label{fig:ArquiteturaHadoop}
\end{figure}

Apesar de existirem dois tipos de escalonamento no Hadoop, o escalonamento com mais opções de alteração é o de aplicações. O Hadoop disponibiliza alguns escalonadores de aplicação, os quais serão referidos apenas por escalonadores a partir de agora. 

O escalonador mais simples é o Hadoop Internal Scheduler, é um escalonador que utiliza o algoritmo FIFO e tem boa performance em \textit{clusters} onde não existe competição por recursos. Outro escalonador disponível é o Fair Scheduler, utilizado principalmente para o processamento de lotes de aplicações pequenas e rápidas. Este escalonador utiliza um escalonamento de dois níveis, buscando a divisão justa dos recursos \cite{FairScheduler}. A terceira opção, e também o padrão do Hadoop nas últimas versões, é o Capacity Scheduler. O Capacity Scheduler foi projetado para a utilização compartilhada do Hadoop e busca a maximização do \textit{throughput} e da utilização do \textit{cluster}. Seu funcionamento baseia-se em garantias mínimas de capacidade para os usuários, deslocando as capacidades dos usuários inativos para aqueles que estão utilizando o \textit{cluster}. Esta estratégia fornece elasticidade com um bom custo benefício \cite{CapacityScheduler}.

A existência destes escalonadores adiciona flexibilidade no gerenciamento do \textit{framework}. Apesar disso, os escalonadores disponíveis não detectam nem reagem à dinamicidade e heterogeneidade do ambiente, um requisito presente em ambientes pervasivos.

\subsection{ZooKeeper}
O ZooKeeper é um projeto da Apache e possui compatibilidade com o Hadoop. Inicialmente, o ZooKeeper foi implementado como um componente do Hadoop e virou um projeto próprio conforme cresciam suas funcionalidades e sua utilização em outras aplicações. Ainda, o ZooKeeper fornece ferramentas eficientes, confiáveis e tolerantes à falha para a coordenação de sistemas distribuídos \cite{Hunt2010}. No caso deste trabalho, utiliza-se os serviços do ZooKeeper para monitorar e transmitir as informações de contexto coletadas nos nós escravos.


\subsection{Trabalhos relacionados}
Ao longo dos anos diversos trabalhos propuseram melhorias para os mecanismos de escalonamento do Hadoop visando uma melhor performance de acordo com suas necessidades. Estas contribuições, na maior parte, podem ser divididas entre dois tipos: propostas de novos métodos de escalonamento ou propostas de melhoria na distribuição de recursos.

Os trabalhos \cite{Kumar2012, Tian2009, Rasooli2012} assumem que a maior parte das aplicações executadas num cluser é periódica e possui cargas de CPU, memória, disco e rede similares. Estas suposições permitem que as aplicações e os nós sejam analizados e classificados de acordo com suas necessidades e suas capacidades nestas características. Uma vez classificados, o escalonamento torna-se um problema de combinar nós e applicações de mesma classificação. Seguindo nesta linha, o trabalho \cite{Isard2009} propõe a utilização de um gráfo de capacidade-demanda que auxilia o cálculo do escalonamento ótimo com base em uma função de custo.

Embora os trabalhos apresentados até aqui focam na melhora da perfromance através da utilização de informação estática sobre recursos e aplicações, existem trabalhos que buscaram incoporar informações sobre as tarefas nas suas propostas. Os trabalhos \cite{Zaharia2008, Chen} tentaram melhorar a distribuição das tarefas de uma aplicação buscando reduzir seu tempo de resposta em grandes \textit{clusters}. Os autores em \cite{Zaharia2008} utilizam heuristicas para inferir o progresso estimado de tarefas e fazer decisões sobre o lançamento de tarefas especulativas. Tarefas especulativas são cópias de tarefas já inicializadas quando existe suspeita de falha na tarefa original ou simplesmente a existência de lentidão no processamento. Já o trabalho \cite{Chen}, propõe a utilização de dados históricos de execução para melhorar a tomada de decisões.

O resultado final da utilização dos dois métodos -- novos métodos de escalonamento e melhoria na distribuição de recursos -- é um rebalanceamento de carga, forçando nós mais rápidos a processarem mais dados e diminuindo a carga de trabalho em nós mais lentos. O trabalho \cite{Sandholm2010} busca o rebalanceamento de carga através de um sistema baseado na lei de oferta e demanda, permitindo que cada usuário influencie diretamente o escalonamento por meio de suas taxas de gasto. O principal objetivo é para permitir um compartilhamento de recursos dinâmico e baseado em preferências que os próprios usuários configuram.

Há também o trabalho \cite{Xie2010}, que tenta fornecer uma melhora na performance em aplicações através da melhora na colocação dos dados, utilizando principalmente a localização de dados como informação para a tomada de decisão. O ganho de performance é alcançado através, também, do rebalanceamento de carga nos nós. Esta proposta reduz o número de tarefas especulativas e transferência de dados pela rede.

Com uma proposta diferente das demais, o trabalho \cite{Marozzo2012} utiliza uma estrutura P2P para organizar o \textit{cluster}. Nesta proposta, os nós podem mudar de função (mestre/ escravo) ao longo do tempo e podem realizar as duas funções ao mesmo tempo, uma vez que a estrutura está ligada com as aplicações e não com o \textit{cluster}. O objetivo deste trabalho foi a adaptação do paradigma de MapReduce a um ambiente P2P. Porém, esta proposta tem foco na disponibilização de uma infra-estrutura resiliente e não explora o escalonamento de aplicações e tarefas.

%Nota-se que a maior parte dos trabalhos citados previamente não consideram o estado atual dos recursos. Nestes trabalhos, recursos são descritos, não observados. Contudo, a computação sensível ao contexto tem demonstrado que esta observação é possível e que o ambiente de execução pode influenciar o comportamento da aplicação \cite{Baldauf}. A partir desta afirmação, a pergunta é: o escalonamento de MapReduce pode ser melhorado através da observação do ambiente de execução?



\section{Desenvolvimento}
Através de um estudo aprofundado do escalonamento do Apache Hadoop, identificou-se uma estratégia para melhoria no processo sem a inserção de métodos intrusivos ou grande modificação nas políticas de escalonamento já implementadas no \textit{framework}. A implementação realizada pode ser separada em duas tarefas distintas, coleta de dados e transmissão de dados.

\subsection{Coletor de contexto}
O Apache Hadoop utiliza arquivos XML como método de configuração do \textit{cluster}, cada nó possui alguns arquivos de configuração e cada arquivo possui diversas propriedades que podem ser alteradas. As informações referentes aos recursos disponíveis em dado nó também estão dentro deste conjunto de propriedades, forçando o administrador a configurar um arquivo para cada nó do \textit{cluster}. Ainda, estas informações são transmitidas ao escalonador somente na inicialização do serviço, não ocorrendo qualquer tipo de atualização até que o serviço seja reinicializado. Estas limitações são gravíssimas num ambiente pervasivo, o qual sofre alterações durante a execução de uma aplicação, e portanto, necessita de um mecanismo que atualize as informações durante a execução.

Para solucionar este problema optou-se pela integração de um módulo de coleta de dados no Hadoop, o qual permite a coleta das informações sobre os recursos em um dado momento. O coletor foi desenvolvido para o projeto PER-MARE \cite{PER-MARE}
% e seu diagrama de classe pode ser visualizado na Figura \ref{fig:collector}. O módulo de coleta 
e é baseado na API padrão de monitoramento do Java \cite{Oracle} permitindo coletar facilmente as informações de um nó sem a adição de bibliotecas externas. Esta API permite que informações como o número de processadores (cores) e a memória do sistema sejam identificadas, através da utilização de um conjunto de interfaces e classes abstratas que generalizam o processo de coleta. Devido à sua estrutura, pode-se facilmente integrar novos coletores para outras informações caso haja necessidade, como por exemplo a utilização de disco ou CPU.

\subsection{Comunicação entre processos}
Para que as informações adquiridas através do módulo de coleta possam ser utilizadas é necessário que estas cheguem até o processo do escalonador, em execução na máquina que possui o serviço Resource Manager. A escolha para a implementação desta comunicação no sentido escravo-mestre foi feita visando a compatibilidade com o Hadoop e a não intrusão nos processos de comunicação já definidos, portanto, a utilização da API ZooKeeper foi escolhida.

%Na Figura \cite{fig:zk-usage} 
Todos os escravos possuem uma \textit{thread} chamada NodeStatusUpdater, esta \textit{thread} coleta dados sobre a disponibilidade de recursos do nó a cada 30 segundos e, se a quantidade de recursos disponíveis estiver diferente da última leitura, a DHT do ZooKeeper será atualizada. Concorrente a isto, o mestre possui uma \textit{thread} \textit{watcher} que observa a DHT do ZooKeeper e caso a DHT seja atualizada, esta thread será notificada e atualizará as informações no escalonador de acordo com a nova informação recebida pela DHT.

Esta solução implementa a capacidade de observação e atualização da disponibilidade de recursos em tempo real, melhorando a capacidade de adaptação do \textit{framework}.

\section{Resultados e experimentos parciais}
A seguir, encontram-se descritos os experimentos realizados. A descrição foi dividida em duas subseções, uma para explicação do ambiente de testes e outra com resultados e análise.

\subsection{Preparação do ambiente}
Primeiramente, configurou-se o \textit{framework} Hadoop no cluster \textit{genepi} do Grid'5000 \cite{g5k}. O ambiente de execução foi configurado com quatro escravos, cada um possuindo a seguinte configuração: 2 CPUs Intel(R) Xeon(R) E5420 2.50 GHz  (totalizando 8 cores por nó) e 8 GB de memória RAM. Todos nós do experimento possuíam o sistema operacional Ubuntu-x64-12.04, com a JDK 1.8 instalada e a versão 2.6.0 do Hadoop configurada.

O \textit{benchmark} foi feito com a aplicação TeraSort, aplicada a um conjunto de dados de 15GB. Os recursos considerados nos experimentos foram a memória e o número de cores, uma vez que estes são os parâmetros utilizados pelo Capacity Scheduler para a alocação de tarefas (\textit{containers}). Foram tomadas precauções para que nenhum outro serviço ou aplicação influenciasse os testes. As informações sobre a execução dos \textit{containers} foi extraída por meio de análise das logs do Hadoop.

Após a implementação das melhorias no \textit{framework} os seguintes casos de teste foram criados e configurados para os experimentos:

\textbf{Caso A:} representa a situação ideal, na forma de um cluster Hadoop dedicado, onde o usuário possui acesso à todos os recursos do cluster em qualquer momento. Isto implica que os recursos informados ao escalonador \textbf{sempre} corresponderão aos recursos disponíveis para o Hadoop. Consideram-se recursos informados como os dados que o escalonador utiliza para realizar suas políticas de escalonamento, enquanto, recursos disponíveis são aqueles estão livres e/ou sendo utilizados pelo próprio Hadoop. Utilizando uma notação percentual, os recursos informados são de 100\% e os recursos disponíveis são de 100\% durante toda execução.

\textbf{Caso B:} representa a situação decorrente do compartilhamento dos nós do cluster com outros usuários. Como consequência do compartilhamento, é possível que em, algum momento, ocorra uma inconsistência entre a quantidade de recursos informada e disponível. Este caso aplica o comportamento padrão do Hadoop, no qual os recursos são informados por meio de arquivos XML \textbf{somente} na inicialização do serviço e nunca são atualizados. Em notação percentual, os recursos informados são de 100\%, porém os recursos disponíveis são de 50\%. Para simular este caso, optou-se por reduzir o número de recursos disponíveis (através da exclusão de nós) sem alterar a informação passada ao escalonador no Caso A.

\textbf{Caso C:} repete as especificações do Caso B, porém possui a implementação da proposta na forma de coletores de contexto e comunicação nós-escalonador. Este caso simula quando uma outra aplicação é lançada \textbf{antes} da ocorrência da coleta e transmissão de dados, ou seja, quando um novo \textit{job} for submetido ao \textit{cluster}, este já estará com os dados atualizados. Em notação percentual, os recursos informados são de 50\% e os recursos disponíveis são de 50\%.

\textbf{Caso D:} representa uma extensão do Caso C em que a inicialização de outra aplicação ocorre \textbf{após} a coleta e transmissão dos dados e \textbf{antes} da submissão de um \textit{job}, ou seja, o \textit{job} será lançado numa situação onde o cluster possui a informação errada (Caso B) e terá de se adaptar à nova configuração dos recursos (Caso C) durante a execução. Em notação percentual, os recursos informados no início do \textit{job} são de 100\%, enquanto os recursos disponíveis são de 50\%. Após a coleta e transmissão de dados os recursos informados também passam a ser 50\%.

\subsection{Resultados e análise}
Os resultados dos experimentos estão resumidos na Tabela \ref{tab:resumo} e na Figura \ref{fig:gantts}. Na Tabela \ref{tab:resumo}, a primeira coluna representa os casos explicados na seção anterior, a segunda coluna representa o tempo total utilizado por todas as tarefas de Map. A terceira coluna representa o tempo médio de execução das tarefas de Map. A quarta coluna representa o desvio padrão do tempo médio de cada caso. A última coluna representa o número de tarefas especulativas lançadas.

Como mencionado anteriormente todas tarefas são processadas em \textit{Containers}, porém alguns destes não são afetados pelo escalonamento como por exemplo o ApplicationMaster e as tarefas de Reduce. Por esta razão estas tarefas foram ignoradas e a análise foi feita como foco nas tarefas de Map, as quais são afetadas pelo escalonamento sensível ao contexto.

\begin{table}[h]
\caption{Resumo dos resultados} \label{tab:resumo}
\begin{tabular*}{\hsize}{@{\extracolsep{\fill}}ccccc@{}}
\hline
Caso & Tempo total({\it{s}}) & Tempo médio ({\it{s}}) & Desvio padrão & Tarefas especulativas\\
\hline
A & 149 & 39.47 & 15.73\% & 2\\
B & 788 & 222.97 & 59.86\% & 1\\
C & 348 & 38.38 & 18.09\% & 3\\
D & 477 & 68.42 & 29.91\% & 1\\
\hline
\end{tabular*}
\end{table}

\begin{figure}[!ht]
\centering
\includegraphics[width=1\textwidth]{figs/todos.png}
\caption{Diagramas de Gantt dos experimentos}
\label{fig:gantts}
\end{figure}

Foram gerados quatro diagramas de Gantt, um para cada caso. Nestes diagramas, cada linha representa os recursos de um nó do cluster consolidados por escala de cor. Quanto mais escuro o tom maior a carga de processamento, sendo o tom preto uma indicação de dezesseis containers em execução enquanto o tom branco representa zero containers. Ainda, cada linha é segmentada para indicar o término ou início de um \textit{container} naquele instante. Os diagramas estão com escala em segundos e todos vão de zero a setecentos e oitenta segundos. Como mencionado na descrição dos casos, os casos B, C e D executam com apenas metade dos nós do caso A para simular a redução dos recursos. 

Pela análise da Tabela \ref{tab:resumo}, é possível notar que os casos A e C, onde os recursos reais são conhecidos antes do início das aplicações, possuem os menores tempo médio de execução e desvio padrão. Isto deve-se ao fato que estes nós nunca foram sobrecarregados, já que o escalonador possuia a informação correta. É possível notar este mesmo comportamento nos diagramas, onde os casos A e C possuem tons similares. Além disso, o caso C apresenta o comportamento esperado, uma vez que possuía metade dos recursos de A e demorou o dobro do tempo. Ainda na Tabela \ref{tab:resumo} também é possível notar que a quantidade de tarefas especulativas lançadas estavam entre 1 e 3 em todos casos, apesar de inicialmente parecer uma surpresa nos casos B e D é um comportamento esperado, uma vez que a decisão de lançar ou não uma tarefa especulativa é baseada numa comparação com as outras tarefas em execução, e nestes casos todas tarefas estavam lentas.

Nota-se também que os casos B e D possuem um tom escuro no início, significando que dezesseis containers (o dobro da capacidade real) estão sendo executados simultaneamente. Ainda, os primeiros containers nos casos A e C levaram em média 20 segundos para executar enquanto no caso B foram necessários 70 segundos, evidenciando uma sobrecarga nos nós. Embora tanto B quanto D possuísem as mesmas condições inicialmente (recursos disponíveis de 50\% e recursos informados de 100\%), o caso D demorou menos tempo para completar. Este melhora foi possível devido à coleta dos recursos atualizados e informação ao escalonador, permitindo que este reorganizasse as tarefas após o primeiro conjunto terminasse para que não houvesse sobrecarga. É possível confirmar esta afirmação ao comparar os tons do caso D, escuros somente no início, com os do caso B, escuros durante toda execução devido à falta de informação atualizada. Embora o escalonador não faça preempção de tarefas, é possível notar uma melhora de performance de cerca de 40\% baseada unicamente no fato do escalonador evitar a sobrecarga dos nós.

Os casos C e D mostram que atualizações de contexto regulares contribuem para a redução do tempo de execução num cluster dinâmico que utiliza o Hadoop. Provou-se que, mesmo iniciando a execução no pior caso possível, a atualização de informações auxilia o escalonador a minimizar o tempo de execução. A solução proposta neste trabalho contribui tanto com o fornecimento de informação correta antes do início da execução quanto com a adaptação da execução às variações de recursos.


\section{Próximas atividades}
O planejamento das próximas atividades inclui a execução de novos testes com características de carga de trabalho diferentes (CPU-Bound, IO-Bound, etc.) nos quatro casos já apresentados, além da inclusão de dois novos casos referentes à agregação de recursos no decorrer da execução. O intuito de novos testes, é para confirmar se a solução adotada apresenta uma melhora no desempenho para apenas um tipo de carga de trabalho ou para a maioria delas.

Para estes novos testes, optou-se por utilizar a ferramenta HiBench que é um pacote de \textit{benchmarks} para \textit{clusters} Hadoop, incluindo tanto micro-benchmarks quanto aplicações reais \cite{hibench}. O Hibench possui \textit{benchmarks} das categorias: \textit{web search} (Page Rank e Nutch Indexing), aprendizagem de máquina (classificação bayesiana e K-means), pesquisa analítica (Hive Join e Hive Aggregation). Esta diversidade de aplicações apresenta testes com cargas de trabalho variadas, fornecendo um instrumento de teste adequado para a confirmação da utilidade das melhorias implementadas.


%
%\begin{figure}[ht]
%\centering
%\includegraphics[width=.5\textwidth]{fig1.jpg}
%\caption{A typical figure}
%\label{fig:exampleFig1}
%\end{figure}
%
%\begin{figure}[ht]
%\centering
%\includegraphics[width=.3\textwidth]{fig2.jpg}
%\caption{This figure is an example of a figure caption taking more than one
%  line and justified considering margins mentioned in Section~\ref{sec:figs}.}
%\label{fig:exampleFig2}
%\end{figure}

%\begin{table}[ht]
%\centering
%\caption{Variables to be considered on the evaluation of interaction
%  techniques}
%\label{tab:exTable1}
%\includegraphics[width=.7\textwidth]{table.jpg}
%\end{table}


\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
