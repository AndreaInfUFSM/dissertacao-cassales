\chapter{Introdução}
\label{chap:Intro}
Apache Hadoop é um \textit{framework} de computação paralela e distribuída para processamento de grandes conjuntos de dados, seguindo o paradigma de programação \mbox{MapReduce} \cite{Dean2008}. O Apache Hadoop foi concebido para ser escalável de um único servidor a milhares de máquinas, cada uma oferecendo processamento e armazenamento local. Esta capacidade de utilizar grande quantidade de \textit{hardware} barato e a crescente importância do processamento de dados não estruturados tornaram o Apache Hadoop uma ferramenta relevante no mercado \cite{Su}.

%cite \cite{Dean2008}
%citet \citet{Dean2008}
%cite author \citeauthor{Dean2008}
%cite year par \citeyearpar{Dean2008}
%cite num \citenum{Dean2008}
%
%\begin{quote}
%quote
%\end{quote}
%
%\begin{quotation}
%quotation
%\end{quotation}

Sem uma configuração específica pelo administrador, o Apache Hadoop assume que um \textit{cluster} homôgeneo está sendo utilizado para a execução de aplicações MapReduce. Uma vez que o desempenho geral do \textit{cluster} está ligado ao escalonamento de tarefas, o desempenho do Hadoop pode diminuir significativamente quando executado em ambientes que não satisfaçam a suposição feita no projeto do \textit{framework}, ou seja, em ambientes dinâmicos ou heterogêneos \cite{Kumar2012}.

Esta é uma preocupação especial quando deseja-se utilizar o Hadoop em infra-estruturas não-dedicadas tais como \emph{grids} pervasivos, uma vez que o custo de aquisição e manutenção de um \textit{cluster} dedicado continua alto e dissuasivo para muitas organizações. De acordo com \citet{Parashar2010}, \emph{grids} pervasivos representam a generalização  extrema do conceito de \emph{grid} por possuírem recursos pervasivos, ou seja, recursos computacionais ociosos que são incorporados ao ambiente com objetivo de processar tarefas de maneira distribuída. 

Estes \emph{grids} são formados por recursos existentes (desktops, servidores, etc.) que ocasionalmente contribuem para o seu poder de processamento. Estes recursos são inerentemente heterogêneos e potencialmente móveis, entrando e saindo do \emph{grid} dinamicamente. Sabendo disto, é possível afirmar que \emph{grids} pervasivos são, em essência, ambientes heterogêneos, dinâmicos e compartilhados. Isso torna o gerenciamento dos recursos complexo e, quando executado de maneira ineficiente, diminui  o desempenho do escalonamento de tarefas \cite{Nascimento}. Um ambiente que possui diversas características em comum com \emph{grids} pervasivos são \textit{clusters} criados com os computadores de uma pequena rede empresarial. Ainda que estes possuam uma quantidade de máquinas muito inferior, sua utilização é viável e consiste de uma alternativa mais barata para atingir os objetivos se a demanda por processamento não for demasiadamente elevada.

%TODO citar os demais ou reduzir o número de trabalhos aqui.
Muitos trabalhos propuseram-se a melhorar a adaptabilidade do \textit{framework} Apache Hadoop em ambientes que divergem da suposição inicial, cada um possuindo sua própria proposta e objetivos \cite{Kumar2012} \cite{Zaharia2008} \cite{Rasooli2012} \cite{Sandholm2010} \cite{3PGCIC}. Em geral, os trabalhos dependem da aquisição de algum dado de contexto e subsequente tomada de decisão para maximização de algum objetivo específico. Contudo, as iniciativas feitas com intuito de suportar ambientes com compartilhamento são mais escassas.

Ainda que o Apache Hadoop possua tolerância a falhas, ele não é capaz de se adaptar a variações de recursos ao longo do tempo e sua configuração é baseada em edição de arquivos. Além disso, os procedimentos de instalação forçam o administrador a definir manualmente as características de cada recurso em potencial, como a memória e o número de \textit{cores} de cada máquina, tornando a tarefa difícil e demorada em ambientes heterogêneos. Todos estes fatores tornam a utilização do Hadoop em ambientes voláteis um desafio, muitas vezes impossibilitando sua utilização devido à sua incapacidade de adaptação. Assim, para tornar esta adaptação possível, é necessário introduzir no Hadoop maneiras de torná-lo consciente do ambiente e reagir às suas variações, ou seja, introduzir mecanismos sensíveis ao contexto para aumentar sua adaptabilidade.

Sendo assim, este estudo propõe-se a aumentar a adaptabilidade dos mecanismos de escalonamento do Apache Hadoop utilizando coleta e transmissão de dados de contexto como meio para solucionar os problemas gerados pelo compartilhamento de nós do \textit{cluster}. Buscou-se atingir este objetivo com o mínimo possível de intrusão e alterações nos mecanismos chave de escalonamento. A coleta de dados é feita com base no tempo médio de duração dos \textit{containers} em execução e a informação só é transmitida caso hajam alterações na capacidade total de \textit{containers} dos nós em relação à última coleta realizada. A transmissão de dados ocorre por meio dos mecanismos oferecidos pelo ZooKeeper: quando ocorre alguma alteração, o escalonador é alertado e realiza uma atualização nas informações pertinentes. A solução implementada apresenta melhorias de até 40\% em alguns casos testados, os quais utilizam aplicações com características diferentes (CPU-bound, I/O-bound, CPU e I/O-bound), provando ser uma alternativa viável para o aumento da adaptabilidade do Apache Hadoop.

%The rest of the paper is organized as follows: Section \ref{sec:refteo} presents Apache Hadoop architecture and scheduling mechanisms. Section \ref{sec:related} discusses related work, focusing on
%context-awareness and on other works that try to improve Hadoop schedulers. Section \ref{sec:desenv} presents our proposal of context-aware scheduling, while Section \ref{sec:exper} presents the experiments conducted and the achieved results. We finally conclude this paper in Section \ref{sec:concl}.
%
%%-------------------------------------------------------------------
%\section{Objetivo Principal}
%
%O objetivo principal deste trabalho é solucionar problemas de escalonamento causados pelo compartilhamento do \textit{cluster}. Utiliza-se de sensibilidade ao contexto para melhorar a adaptabilidade do \textit{cluster} por meio do envio de informações atualizadas, com respeito à disponibilidade de recursos em cada nó escravo, ao escalonador.
%
%%-------------------------------------------------------------------
%\section{Objetivos Secundários}
%
%Como objetivos secundários deste trabalho estão o estudo e identificação de outros fatores possivelmente impactantes no desempenho do escalonamento, mas que não diretamente ligados com o compartilhamento dos recursos. Exemplos destes fatores são: relação entre tarefas especulativas e tarefas rack-local
