\chapter{Introdução}
\label{chap:Introducao}
Uma das maiores empresas de tecnologia da atualidade, o Google \cite{Google}, teve a ideia inicial de uma maneira de processar o grande volume de dados que era gerado em seus servidores. Tratava-se de uma abordagem que posteriormente ficaria conhecida como \emph{MapReduce}, constituída de duas etapas, cada uma utilizando uma função já conhecida das linguagens funcionais.

Paralelamente a isso, um projeto liderado pela Yahoo! \cite{Yahoo} também começava uma implementação de \emph{MapReduce} para seu sistema, que mais tarde tornou-se um projeto separado conhecido como \emph{Apache Hadoop} \cite{Hadoop}.

Hoje o \emph{framework} \emph{Apache Hadoop} possui uma comunidade muito ativa tanto de desenvolvedores como usuários, porém algumas de suas características da época de sua criação não foram alteradas, entre elas o seu foco em ambientes homogêneos. Sabe-se que manter um ambiente totalmente homogêneo torna-se complicado com o passar do tempo, pois é comum a substituição de peças e de máquinas defeituosas por componentes mais atuais.

O desempenho das tarefas de \emph{MapReduce} está fortemente atrelada ao escalonador do Hadoop\cite{CASH}. Por tratar-se de um projeto de \emph{open-source}, é possível criar um novo escalonador que se adapte e faça uso da heterogeneidade do ambiente de forma a melhorar o desempenho.

Uma característica chave para adaptação do \emph{framework} Hadoop para ambientes heterogêneos é a sensibilidade ao contexto. A definição do contexto pode variar de uma aplicação para outra, mas de maneira geral é uma informação que a aplicação irá utilizar como base para a tomada de suas decisões. Quando uma aplicação é sensível ao contexto, ela irá detectar e adaptar-se às mudanças que ocorram no ambiente. \cite{Manuele}.

No âmbito do presente trabalho, o contexto ao qual a aplicação deverá se adaptar são as configurações físicas das máquinas que compõem um \emph{cluster} Hadoop, permitindo às tarefas que demandem maior quantidade de recursos sejam executadas em máquinas mais potentes do \emph{cluster}. Num grau de complexidade maior, o qual o presente trabalho está inserido, existe um projeto \cite{PER-MARE} que tem por objetivo adaptar-se a mais variações do ambiente, como a inserção e remoção de nós em tempo de execução.

%TODO: citar projeto PER-MARE

%-------------------------------------------------------------------
\section{Objetivos}
\subsection{Objetivo Geral}
O objetivo geral deste trabalho é o desenvolvimento de um novo escalonador sensível ao contexto para o \emph{Apache Hadoop}, tornando este \emph{framework} capaz de adaptar-se a ambientes de execução heterogêneos.

%-------------------------------------------------------------------
\subsection{Objetivos Específicos}
\begin{itemize}
   \item Estudar os \emph{schedulers} do \emph{Apache Hadoop}.
   \item Desenvolvimento de um escalonador base.
   \item Estudo da relação das Máquinas Virtuais(MVs) com o hardware da máquina.
   \item Desenvolvimento de um novo escalonador que utilize as informações das máquinas físicas.
   \item Testes do novo escalonador.
\end{itemize}

%-------------------------------------------------------------------
\section{Justificativa}

Atualmente, algumas tarefas de processamento que outrora eram destinadas a grandes \emph{mainframes} e servidores está gradualmente passando para \emph{clusters} de computadores de preços acessíveis e que são facilmente obtidos no mercado. Como prova disso, está a crescente utilização de \emph{frameworks} em \emph{clusters}, sendo que o \emph{Apache Hadoop} também segue essa linha. 

Apesar de ter como alvo os \emph{clusters}, o \emph{Apache Hadoop} foi implementado sobre a suposição de que todos os nós em um \emph{cluster} seriam homogêneos, fazendo desse um requisito que muitas vezes se torna complicado de ser satisfeito dentro de um \emph{cluster}.

O presente trabalho é relevante, pois seu objetivo está baseado na adaptação e melhoria de uma tecnologia já existente. Com o desenvolvimento de um novo escalonador, não só os \emph{clusters} utilizadores do \emph{Apache Hadoop} terão uma maneira de aproveitar melhor suas máquinas, como o próprio \emph{framework} tornar-se-á mais versátil e capaz de adaptar-se a ambientes heterogêneos.
