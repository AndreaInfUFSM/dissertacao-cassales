\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

%\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}  

     
\sloppy

\title{Seminário de Andamento\\Escalonamento Adaptativo para o Apache Hadoop}

\author{Guilherme Weigert Cassales\inst{1}, Andrea Schwertner Charão\inst{1}}

\address{Laboratório de Sistemas Computacionais\\Universidade Federal de Santa Maria (UFSM)\\Santa Maria -- RS -- Brazil
  \email{\{cassales,andrea\}@inf.ufsm.br}
}

\begin{document} 

\maketitle

\begin{abstract}
This article proposes to improve Apache Hadoop scheduling through the usage of context-awareness. Apache Hadoop is the most popular implementation of the MapReduce paradigm for distributed computing, but its design doesn't adapt automatically to computing nodes' context and capabilities. By introducing context-awareness into Hadoop, we intent to dynamically adapt its scheduling to the execution environment. The solution has been incorporated into Hadoop and evaluated through controlled experiments. The experiments demonstrate that context-awareness provides comparative performance gains, especially when part of the resources disappear during execution.
\end{abstract}
     
\begin{resumo} 
Este trabalho propõe uma melhoria no escalonamento do Apache Hadoop através da utilização de informações de contexto sobre os nós de um \textit{cluster}. O Apache Hadoop é a implementação mais popular do paradigma MapReduce em computação distribuída, porém possui alguns problemas de performance em ambientes dinâmicos. Ao introduzir sensibilidade ao contexto no Hadoop, espera-se que o escalonamento dos \textit{jobs} adapte-se às mudanças do ambiente. A solução foi implementada no Apache Hadoop e testes preliminares indicam que houve uma melhora de performance, especialmente quando parte dos recursos desaparece durante a execução.
\end{resumo}


\section{Introdução}
Apache Hadoop is a framework for distributed and parallel computing, implementing the MapReduce programming paradigm, which aims at processing big data sets. Hadoop is designed to scale up from a single server to thousands of machines, each offering local computation and storage. Without specific configuration by the administrator, Apache Hadoop supposes the use of dedicated homogeneous clusters for executing MapReduce applications. As the overall performance depends on the task scheduling, Hadoop performance may be seriously impacted when running on heterogeneous and dynamic environments, for which it was not designed for.

\section{Referencial teórico}


\subsection{Sensibilidade ao contexto}
...

\subsection{Apache Hadoop e escalonamento}
O \textit{framework} Apache Hadoop é organizado numa arquitetura de mestre-escravo e possui dois serviços principais, o serviço de armazenamento (HDFS) e o de processamento (YARN). Cada serviço possui mestre e escravos independentes como apresentado na Figura \ref{fig:Arch}, onde é possível notar que os serviços NameNode e ResourceManager, mestres do HDFS e YARN respectivamente, e os seus respectivos escravos DataNode e NodeManager. Outro componente que aparece na figura é o ApplicationMaster, este componente é responsável pelo gerenciamento interno de cada job, também chamado de escalonamento de \textit{tasks}. Entende-se \textit{task} como uma fração do processamento do \textit{job}, ou seja, cada tarefa de Map ou Reduce corresponde a uma \textit{task}. Enquanto o ApplicationMaster gerencia as \textit{tasks}, é função do ResourceManager gerenciar os \textit{jobs}. Finalmente, o último componente a aparecer na figura é o Container, o qual representa uma alocação de recursos em um nó qualquer do cluster. Todas as \textit{tasks} são executadas em containers.

Apesar de existirem dois tipos de escalonamento no Hadoop, o escalonamento com mais opções de alteração é o de \textit{jobs}. O Hadoop disponibiliza alguns escalonadores de \textit{job}, os quais serão referidos apenas por escalonadores a partir de agora. 

O escalonador mais simples é o Hadoop Internal Scheduler, é um escalonador de fila que utiliza o algoritmo FIFO e tem boa performance em \textit{clusters} onde não existe competição por recursos. Outro escalonador disponível é o Fair Scheduler, utilizado principalmente para o processamento de lotes de \textit{jobs} pequenos e rápidos. Este escalonador utiliza um escalonamento de dois níveis, buscando a divisão justa dos recursos \cite{FairScheduler}. A terceira opção, e também o padrão do Hadoop nas últimas versões, é o CapacityScheduler. O CapacityScheduler foi projetado para a utilização compartilhada do Hadoop e busca a maximização do \textit{throughput} e da utilização do cluster. Seu funcionamento se baseia em garantias mínimas de capacidade para os usuários, deslocando as capacidades dos usuários inativos para aqueles que estão utilizando o \textit{cluster} provendo elasticidade com um bom custo benefício \cite{CapacityScheduler}.

A existência destes escalonadores permite um gerenciamento flexível do \textit{framework}. Apesar disso, os escalonadores disponíveis não detectam nem reagem à dinamicidade e heterogeneidade do ambiente, uma preocupação presente em ambientes pervasivos.

\subsection{ZooKeeper}
...

\subsection{Trabalhos relacionados}
...

\section{Desenvolvimento}
Através de um estudo aprofundado do escalonamento do Apache Hadoop, identificou-se uma estratégia para melhoria no processo sem a inserção de métodos intrusivos ou grande modificação nas políticas de escalonamento já implementadas no \textit{framework}. A implementação realizada pode ser separada em duas tarefas distintas, coleta de dados e transmissão de dados.

\subsection{Coletor de contexto}
O Apache Hadoop utiliza arquivos XML como método de configuração do \textit{cluster}, cada nó possui alguns arquivos de configuração e cada arquivo possui diversas propriedades que podem ser alteradas. As informações referentes aos recursos disponíveis em dado nó também estão dentro deste conjunto de propriedades, forçando o administrador a configurar um arquivo para cada nó do \textit{cluster}. Além disso, estas informações são transmitidas ao escalonador somente na inicialização do serviço, não ocorrendo qualquer tipo de atualização até que o serviço seja reiniciado. Estas limitações provam ser gravíssimas num ambiente pervasivo, que sofre alterações durante a execução de uma aplicação, portanto, precisa-se de um mecanismo que atualize as informações durante a execução.

Para solucionar este problema optou-se pela integração de um módulo de coleta de dados no Hadoop, que permite a coleta das informações sobre os recursos em um dado momento. O coletor foi desenvolvido para o projeto PER-MARE \cite{PER-MARE} e seu diagrama de classe pode ser visualizado na Figura \ref{fig:collector}. O módulo de coleta é baseado na API padrão de monitoramento do Java \cite{java-api} que permite facilmente coletar de um nó sem a adição de bibliotecas externas. Esta API permite que informações como o número de processadores (cores) e a memória do sistema sejam identificadas, através da utilização de um conjunto de interfaces e classes abstratas que generalizam o processo de coleta. Devido à sua estrutura, pode-se facilmente integrar novos coletores para outras informações caso haja necessidade, como por exemplo a utilização de disco ou CPU.

\subsection{Comunicação entre processos}
Para que as informações adquiridas através do módulo de coleta possam ser utilizadas é necessário que estas cheguem até o processo do escalonador, que está sendo executado na máquina mestre do \textit{cluster}. A escolha para a implementação desta comunicação escravo-mestre foi feita visando a compatibilidade com o Hadoop e a não intrusão nos processos de comunicação já definidos, portanto, escolheu-se pela utilização da API ZooKeeper \cite{ZooKeeper}.

O ZooKeeper é, também, um projeto da Apache e possui compatibilidade com o Hadoop. Inicialmente, o ZooKeeper foi implementado como um componente do Hadoop e virou um projeto próprio conforme cresciam suas funcionalidades e sua utilização em outras aplicações. Ainda, o ZooKeeper fornece ferramentas eficientes, confiáveis e tolerantes à falha para a coordenação de sistemas distribuídos. No caso deste trabalho, utiliza-se os serviços do ZooKeeper para monitorar e transmitir as informações de contexto coletadas nos nós escravos.

Na Figura \cite{fig:zk-usage} todos os escravos possuem uma \textit{thread} chamada NodeStatusUpdater, esta \textit{thread} coleta dados sobre a disponibilidade de recursos do nó a cada 30 segundos e, se a quantidade de recursos disponíveis estiver diferente da última leitura, a DHT do ZooKeeper será atualizada. Concorrente a isto, o mestre possui uma \textit{thread} \textit{watcher} que observa a DHT do ZooKeeper e caso a DHT seja atualizada, esta thread será notificada e atualizará as informações no escalonador de acordo com a nova informação recebida pela DHT.

Esta solução implementa a capacidade de observação e atualização da disponibilidade de recursos em tempo real, melhorando a capacidade de adaptação do \textit{framework}.

\section{Resultados e experimentos parciais}
A seguir, encontram-se descritos os experimentos realizados. A descrição foi dividida em duas subseções, uma para explicação do ambiente de testes e outra com resultados e análise.

\subsection{Preparação do ambiente}
Primeiramente, configurou-se o \textit{framework} Hadoop no cluster \textit{genepi} do Grid'5000 \cite{g5k}. O ambiente de execução foi configurado com quatro escravos, cada um possuindo a seguinte configuração: 2 CPUs Intel(R) Xeon(R) E5420 2.50 GHz  (totalizando 8 cores por nó) e 8 GB de memória RAM. Todos nós do experimento possuíam o sistema operacional Ubuntu-x64-12.04, com a JDK 1.8 instalada e a versão 2.6.0 do Hadoop configurada.

O \textit{benchmark} foi feito com a aplicação TeraSort, aplicada a um conjunto de dados de 15GB. Os recursos considerados nos experimentos foram a memória e o número de cores, uma vez que estes são os parâmetros utilizados pelo Capacity Scheduler para a alocação de \textit{tasks} (\textit{containers}). Foram tomadas precauções para que nenhum outro serviço ou aplicação influenciasse os testes. As informações sobre a execução dos \textit{containers} foi extraída por meio de análise das logs do Hadoop.

Após a implementação das melhorias no \textit{framework} os seguintes casos de teste foram criados e configurados para os experimentos:

\textbf{Caso A:} representa a situação ideal, na forma de um cluster Hadoop dedicado, onde o usuário possui acesso à todos os recursos do cluster em qualquer momento. Isto implica que os recursos informados ao escalonador \textbf{sempre} corresponderão aos recursos disponíveis para o Hadoop. Consideram-se recursos informados como os dados que o escalonador utiliza para realizar suas políticas de escalonamento, enquanto, recursos disponíveis são aqueles estão livres e/ou sendo utilizados pelo próprio Hadoop. Utilizando uma notação percentual, os recursos informados são de 100\% e os recursos disponíveis são de 100\% durante toda execução.

\textbf{Caso B:} representa a situação decorrente do compartilhamento dos nós do cluster com outros usuários. Como consequência do compartilhamento, é possível que em, algum momento, ocorra uma inconsistência entre a quantidade de recursos informada e disponível. Este caso aplica o comportamento padrão do Hadoop, no qual os recursos são informados por meio de arquivos XML \textbf{somente} na inicialização do serviço e nunca são atualizados. Em notação percentual, os recursos informados são de 100\%, porém os recursos disponíveis são de 50\%. Para simular este caso, optou-se por reduzir o número de recursos disponíveis (através da exclusão de nós) sem alterar a informação passada ao escalonador no Caso A.

\textbf{Caso C:} repete as especificações do Caso B, porém possui a implementação da proposta na forma de coletores de contexto e comunicação nós-escalonador. Este caso simula quando uma outra aplicação é lançada \textbf{antes} da ocorrência da coleta e transmissão de dados, ou seja, quando um novo \textit{job} for submetido ao \textit{cluster}, este já estará com os dados atualizados. Em notação percentual, os recursos informados são de 50\% e os recursos disponíveis são de 50\%.

\textbf{Caso D:} representa uma extensão do Caso C em que a inicialização de outra aplicação ocorre \textbf{após} a coleta e transmissão dos dados e \textbf{antes} da submissão de um \textit{job}, ou seja, o \textit{job} será lançado numa situação onde o cluster possui a informação errada (Caso B) e terá de se adaptar à nova configuração dos recursos (Caso C) durante a execução. Em notação percentual, os recursos informados no início do \textit{job} são de 100\%, enquanto os recursos disponíveis são de 50\%. Após a coleta e transmissão de dados os recursos informados também passam a ser 50\%.

\subsection{Resultados e análise}
...

\subsection{Próximas atividades}
O planejamento das próximas atividades inclui a execução de novos testes com características de carga de trabalho diferentes (CPU-Bound, IO-Bound, entre outras) nos quatro casos já apresentados, além da inclusão de dois novos casos referentes à agregação de recursos no decorrer da execução. O intuito de novos testes, é para confirmar se a solução adotada apresenta uma melhora no desempenho para apenas um tipo de carga de trabalho ou para a maioria delas.

Para estes novos testes, utilizar-se-á da ferramenta HiBench \cite{sla,...} que fornece diversos \textit{jobs} com características de carga de trabalho distintas. O Hibench é definido como .......

%
%\begin{figure}[ht]
%\centering
%\includegraphics[width=.5\textwidth]{fig1.jpg}
%\caption{A typical figure}
%\label{fig:exampleFig1}
%\end{figure}
%
%\begin{figure}[ht]
%\centering
%\includegraphics[width=.3\textwidth]{fig2.jpg}
%\caption{This figure is an example of a figure caption taking more than one
%  line and justified considering margins mentioned in Section~\ref{sec:figs}.}
%\label{fig:exampleFig2}
%\end{figure}

%\begin{table}[ht]
%\centering
%\caption{Variables to be considered on the evaluation of interaction
%  techniques}
%\label{tab:exTable1}
%\includegraphics[width=.7\textwidth]{table.jpg}
%\end{table}


\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
