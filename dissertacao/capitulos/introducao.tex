\chapter{Introdução}
\label{chap:Intro}
Apache Hadoop é um \textit{framework} de computação paralela e distribuída para processamento de grandes conjuntos de dados e implementa o paradigma de programação \mbox{MapReduce} \cite{Dean2008}. O Apache Hadoop é projetado para ser escalável de um único servidor a milhares de máquinas, cada uma oferecendo processamento e armazenamento local. Esta capacidade de utilizar grande quantidade de \textit{hardware} barato e a crescente importância do processamento de dados não estruturados tornaram o Apache Hadoop uma ferramenta relevante no mercado \cite{Su}.

%cite \cite{Dean2008}
%citet \citet{Dean2008}
%cite author \citeauthor{Dean2008}
%cite year par \citeyearpar{Dean2008}
%cite num \citenum{Dean2008}
%
%\begin{quote}
%quote
%\end{quote}
%
%\begin{quotation}
%quotation
%\end{quotation}

Sem uma configuração específica pelo administrador, o Apache Hadoop assume que um \textit{cluster} homôgeneo está sendo utilizado para a execução de aplicações MapReduce. Uma vez que o desempenho geral do \textit{cluster} está ligado ao escalonamento de tarefas, o desempenho do Hadoop pode diminuir significativamente quando executado em ambientes que não satisfaçam a suposição feita no projeto do \textit{framework}, ou seja, em ambientes dinâmicos ou heterogêneos \cite{Kumar2012}.

Esta é uma preocupação especial quando tenta-se utilizar o Hadoop em grids pervasivos, os quais são uma alternativa aos \textit{clusters} dedicados, uma vez que o custo de aquisição e manutenção de um \textit{cluster} dedicado continua alto e dissuasivo para muitas organizações. De acordo com \cite{Parashar2010}, grids pervasivos representam a generalização  extrema do conceito de grid por possuírem recursos pervasivos, ou seja, recursos computacionais ociosos que são incorporados ao ambiente com objetivo de processar tarefas de maneira distribuída. 

Estes grids podem ser vistos como grids formados por recursos existentes (desktops, servidores, etc.) que ocasionalmente contribuem para o seu poder de processamento. Estes recursos são inerentemente heterogêneos e potencialmente móveis, entrando e saindo do grid dinamicamente. Sabendo disto, é possível afirmar que grids pervasivos são, em essência, ambientes heterogêneos, dinâmicos e compartilhados; tornando o gerenciamento dos recursos complexo e, quando executado de maneira ineficiente, dimnuindo  o desempenho do escalonamento de tarefas \cite{Nascimento}.

%TODO citar os demais ou reduzir o número de trabalhos aqui.
Muitos trabalhos propuseram-se a melhorar a adaptabilidade do \textit{framework} Apache Hadoop em ambientes que divergem da suposição inicial, cada um possuindo sua própria proposta e objetivos \cite{Kumar2012} \cite{Zaharia2008} \cite{Rasooli2012} \cite{Sandholm2010} \cite{3PGCIC}. Em geral, os trabalhos dependem da aquisição de algum dado de contexto e subsequente tomada de decisão para maximização de algum objetivo específico.

Sabe-se que, o Apache Hadoop é baseado em configuração estática de arquivos e que as versões correntes, apesar de possuírem tolerância a falhas, não adaptam-se a variações de recursos ao longo do tempo. Além disso, os procedimentos de instalação forçam o administrador a definir manualmente as características de cada recurso em potencial, como a memória e o número de \textit{cores} de cada máquina, tornando a tarefa difícil e demorada em ambientes heterogêneos. Todos estes fatores impedem a utilização da capacidade total do Hadoop em ambientes voláteis, portanto, é essencial possuir sensibilidade ao contexto para tornar esta adaptação possível.

Este trabalho propõe-se a aumentar a adaptabilidade dos mecanismos de escalonamento do Apache Hadoop utilizando coleta e transmissão de dados de contexto como meio para solucionar os problemas gerados pelo compartilhamento de nós do \textit{cluster}. Buscou-se atingir este objetivo com o mínimo possível de intrusão e alterações nos mecanismos chave de escalonamento. A coleta de dados é feita com base no tempo médio de duração dos \textit{containers} em execução e a informação só é transmitida caso hajam mudanças em relação à última coleta realizada. A transmissão de dados ocorre por meio dos mecanismos oferecidos pelo ZooKeeper, quando ocorre alguma alteração o escalonador é alertado e realiza uma atualização nas informações pertinentes. A solução implementada apresenta melhorias de até 40\% em alguns casos testados, os quais utilizam aplicações com características diferentes (CPU-bound, I/O-bound, CPU e I/O-bound), provando ser uma alternativa viável para o aumento da adaptabilidade do Apache Hadoop.

%The rest of the paper is organized as follows: Section \ref{sec:refteo} presents Apache Hadoop architecture and scheduling mechanisms. Section \ref{sec:related} discusses related work, focusing on
%context-awareness and on other works that try to improve Hadoop schedulers. Section \ref{sec:desenv} presents our proposal of context-aware scheduling, while Section \ref{sec:exper} presents the experiments conducted and the achieved results. We finally conclude this paper in Section \ref{sec:concl}.
%
%%-------------------------------------------------------------------
%\section{Objetivo Principal}
%
%O objetivo principal deste trabalho é solucionar problemas de escalonamento causados pelo compartilhamento do \textit{cluster}. Utiliza-se de sensibilidade ao contexto para melhorar a adaptabilidade do \textit{cluster} por meio do envio de informações atualizadas, com respeito à disponibilidade de recursos em cada nó escravo, ao escalonador.
%
%%-------------------------------------------------------------------
%\section{Objetivos Secundários}
%
%Como objetivos secundários deste trabalho estão o estudo e identificação de outros fatores possivelmente impactantes no desempenho do escalonamento, mas que não diretamente ligados com o compartilhamento dos recursos. Exemplos destes fatores são: relação entre tarefas especulativas e tarefas rack-local