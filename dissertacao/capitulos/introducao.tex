\chapter{Introdução}
\label{chap:Intro}
Apache Hadoop é um \textit{framework} de computação paralela e distribuída para processamento de grandes conjuntos de dados e implementa o paradigma de programação \mbox{MapReduce} \cite{Dean2008}. O Apache Hadoop é projetado para ser escalável de um único servidor a milhares de máquinas, cada uma oferecendo processamento e armazenamento local. Esta capacidade de utilizar grande quantidade de hardware barato e a crescente importância do processamento de dados não estruturados tornaram o Apache Hadoop uma ferramenta relevante no mercado \cite{Su}.

Sem uma configuração específica pelo administrador, o Apache Hadoop assume que está sendo utilizado em um \textit{cluster} homogêneo para execução de aplicações \mbox{MapReduce}. Uma vez que o desempenho geral do \textit{cluster} está ligado ao escalonamento de tarefas, o desempenho do Hadoop pode diminuir significativamente quando executado em ambientes que não satisfaçam a suposição feita no projeto do \textit{framework}, ou seja, em ambientes dinâmicos ou heterogêneos \cite{Kumar2012}.

Esta é uma preocupação especial quando tenta-se utilizar o Hadoop em grids pervasivos. Grids pervasivos são uma alternativa aos \textit{clusters} dedicados, dado que o custo de aquisição e manutenção de um \textit{cluster} dedicado continua alto e dissuasivo para muitas organizações. De acordo com \cite{Parashar2010}, grids pervasivos representam a generalização  extrema do conceito de grid por possuírem recursos pervasivos, ou seja, recursos computacionais ociosos que são incorporados ao ambiente e então requisitados com objetivo de processar tarefas de maneira distribuída. 

Estes grids podem ser vistos como grids formados por recursos existentes (desktops, servidores, etc.) que ocasionalmente contribuem para o poder de processamento do grid. Estes recursos são inerentemente heterogêneos e potencialmente móveis, entrando e saindo do grid dinamicamente. Sabendo disto, é possível afirmar que grids pervasivos são, em essência, ambientes heterogêneos, dinâmicos e compartilhados; tornando o gerenciamento dos recursos complexo e, quando executado de maneira ineficiente, dimnuindo  o desempenho do escalonamento de tarefas \cite{Nascimento}.

%TODO citar demais ou reduzir o número de trabalhos aqui.
Muitos trabalhos propuseram-se a melhorar a adaptabilidade do \textit{framework} Apache Hadoop em ambientes que divergem da suposição inicial, cada um possuindo sua própria proposta e objetivos \cite{Kumar2012, Zaharia2008, Rasooli2012, Sandholm2010, 3PGCIC}. Em geral os trabalhos dependem da aquisição de algum dado de contexto e subsequente tomada de decisão para maximização de algum objetivo específico.

Sabe-se que, o Apache Hadoop é baseado em configuração estática de arquivos e que as versões correntes não adaptam-se a variações de recursos ao longo do tempo. Além disto, os procedimentos de instalação forçam o administrador a definir manualmente as características de cada recurso em potencial, como a memória e o número de cores de cada máquina, tornando a tarefa difícil e demorada em ambientes heterogêneos. Todos estes fatores impedem a utilização da capacidade total do Hadoop em ambientes voláteis, portanto, é essencial possuir sensibilidade ao contexto para tornar esta adaptação possível.

Este trabalho propõe-se a aumentar a adaptabilidade dos mecanismos de escalonamento do Apache Hadoop através da coleta e transmissão de dados de contexto com intuito de solucionar problemas gerados pelo compartilhamento e  pela entrada de novos nós no \textit{cluster}. Buscou-se atingir estes objetivos com o mínimo possível de intrusão e alterações nos mecanismos chave de escalonamento. A coleta de dados é feita com base no tempo médio de duração dos \textit{containers} em execução e a informação só é transmitida caso hajam mudanças em relação à última coleta realizada. A transmissão de dados ocorre por meio de uma tabela Hash distribuída, quando esta tabela é alterada o escalonador é alertado e realiza uma atualização nas informações pertinentes. A solução implementada apresenta melhorias de até 40\% em alguns casos de testes os quais utilizam aplicações com características diferentes (CPU-bound, I/O-bound, CPU e I/O-bound), provando ser uma alternativa viável para o aumento da adaptabilidade do Apache Hadoop.

%The rest of the paper is organized as follows: Section \ref{sec:refteo} presents Apache Hadoop architecture and scheduling mechanisms. Section \ref{sec:related} discusses related work, focusing on
%context-awareness and on other works that try to improve Hadoop schedulers. Section \ref{sec:desenv} presents our proposal of context-aware scheduling, while Section \ref{sec:exper} presents the experiments conducted and the achieved results. We finally conclude this paper in Section \ref{sec:concl}.
%
%%-------------------------------------------------------------------
%\section{Objetivo Principal}
%
%O objetivo principal deste trabalho é solucionar problemas de escalonamento causados pelo compartilhamento do \textit{cluster}. Utiliza-se de sensibilidade ao contexto para melhorar a adaptabilidade do \textit{cluster} por meio do envio de informações atualizadas, com respeito à disponibilidade de recursos em cada nó escravo, ao escalonador.
%
%%-------------------------------------------------------------------
%\section{Objetivos Secundários}
%
%Como objetivos secundários deste trabalho estão o estudo e identificação de outros fatores possivelmente impactantes no desempenho do escalonamento, mas que não diretamente ligados com o compartilhamento dos recursos. Exemplos destes fatores são: relação entre tarefas especulativas e tarefas rack-local